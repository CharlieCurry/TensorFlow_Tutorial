{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手动调整学习率并在TensorBoard中显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7ad1921416f6>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\env\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\env\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\env\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\env\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\env\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000202E578EAC8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000202E7F2E400>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000202E7F2E438>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batchs = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建参数的概要函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对模型的参数进行的统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_info(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean_value = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean_value)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev_value = tf.sqrt(tf.reduce_mean(tf.square(var - mean_value)))\n",
    "        tf.summary.scalar('stddev', stddev_value)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义输入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"input_layer\"):\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    lr = tf.Variable(0.01,tf.float32)\n",
    "    tf.summary.scalar('learning_rate',lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('network'):\n",
    "    with tf.name_scope(\"weights\"):\n",
    "        w = tf.Variable(tf.truncated_normal([784,10], stddev=0.1), name='w')\n",
    "        variable_info(w)\n",
    "    with tf.name_scope('baises'):\n",
    "        b = tf.Variable(tf.zeros([10]) + 0.1, name=\"b\")\n",
    "        variable_info(b)\n",
    "    with tf.name_scope('xw_plus_b'):\n",
    "        a = tf.matmul(x,w) + b\n",
    "    with tf.name_scope('softmax'):\n",
    "        out = tf.nn.softmax(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义交叉熵损失函数与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-ec603635083d>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"loss_train\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y))\n",
    "    train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  定义评价模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    with tf.name_scope(\"correct\"):\n",
    "        correct = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化变量和summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "Cannot set tensorflow.VariableDef.trainable to tf.float32: tf.float32 has type <class 'tensorflow.python.framework.dtypes.DType'>, but expected one of: (<class 'bool'>, <class 'numbers.Integral'>)\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "Cannot set tensorflow.VariableDef.trainable to tf.float32: tf.float32 has type <class 'tensorflow.python.framework.dtypes.DType'>, but expected one of: (<class 'bool'>, <class 'numbers.Integral'>)\n",
      "Iter:  0 Loss:  1.6121478 Acc:  0.8956 lr:  0.001\n",
      "Iter:  1 Loss:  1.5801302 Acc:  0.9101 lr:  0.00095\n",
      "Iter:  2 Loss:  1.567849 Acc:  0.9154 lr:  0.0009025\n",
      "Iter:  3 Loss:  1.5607082 Acc:  0.9202 lr:  0.000857375\n",
      "Iter:  4 Loss:  1.5561568 Acc:  0.9218 lr:  0.00081450626\n",
      "Iter:  5 Loss:  1.5529832 Acc:  0.9238 lr:  0.0007737809\n",
      "Iter:  6 Loss:  1.5498708 Acc:  0.9254 lr:  0.0007350919\n",
      "Iter:  7 Loss:  1.5481093 Acc:  0.9262 lr:  0.0006983373\n",
      "Iter:  8 Loss:  1.547052 Acc:  0.9251 lr:  0.0006634204\n",
      "Iter:  9 Loss:  1.5451214 Acc:  0.9283 lr:  0.0006302494\n",
      "Iter:  10 Loss:  1.5444841 Acc:  0.9275 lr:  0.0005987369\n",
      "Iter:  11 Loss:  1.5434135 Acc:  0.9291 lr:  0.0005688001\n",
      "Iter:  12 Loss:  1.542806 Acc:  0.928 lr:  0.0005403601\n",
      "Iter:  13 Loss:  1.5421013 Acc:  0.9286 lr:  0.0005133421\n",
      "Iter:  14 Loss:  1.541425 Acc:  0.9288 lr:  0.000487675\n",
      "Iter:  15 Loss:  1.5409465 Acc:  0.9302 lr:  0.00046329122\n",
      "Iter:  16 Loss:  1.5402813 Acc:  0.93 lr:  0.00044012666\n",
      "Iter:  17 Loss:  1.5400589 Acc:  0.9302 lr:  0.00041812033\n",
      "Iter:  18 Loss:  1.540115 Acc:  0.9301 lr:  0.00039721432\n",
      "Iter:  19 Loss:  1.5399228 Acc:  0.93 lr:  0.0003773536\n",
      "Iter:  20 Loss:  1.5391417 Acc:  0.931 lr:  0.00035848594\n",
      "Iter:  21 Loss:  1.5389756 Acc:  0.9305 lr:  0.00034056162\n",
      "Iter:  22 Loss:  1.5387868 Acc:  0.9308 lr:  0.00032353355\n",
      "Iter:  23 Loss:  1.5383316 Acc:  0.9308 lr:  0.00030735688\n",
      "Iter:  24 Loss:  1.5382255 Acc:  0.9314 lr:  0.000291989\n",
      "Iter:  25 Loss:  1.5382636 Acc:  0.931 lr:  0.00027738957\n",
      "Iter:  26 Loss:  1.5378859 Acc:  0.9314 lr:  0.0002635201\n",
      "Iter:  27 Loss:  1.5380167 Acc:  0.9306 lr:  0.00025034408\n",
      "Iter:  28 Loss:  1.5379087 Acc:  0.9307 lr:  0.00023782688\n",
      "Iter:  29 Loss:  1.5375823 Acc:  0.9309 lr:  0.00022593554\n",
      "Iter:  30 Loss:  1.5375407 Acc:  0.9307 lr:  0.00021463877\n",
      "Iter:  31 Loss:  1.5373293 Acc:  0.9315 lr:  0.00020390682\n",
      "Iter:  32 Loss:  1.5372176 Acc:  0.9309 lr:  0.00019371149\n",
      "Iter:  33 Loss:  1.5373523 Acc:  0.9309 lr:  0.0001840259\n",
      "Iter:  34 Loss:  1.5373024 Acc:  0.931 lr:  0.00017482461\n",
      "Iter:  35 Loss:  1.5372744 Acc:  0.9309 lr:  0.00016608338\n",
      "Iter:  36 Loss:  1.53704 Acc:  0.9308 lr:  0.00015777921\n",
      "Iter:  37 Loss:  1.5369546 Acc:  0.9309 lr:  0.00014989026\n",
      "Iter:  38 Loss:  1.5369719 Acc:  0.9309 lr:  0.00014239574\n",
      "Iter:  39 Loss:  1.5368526 Acc:  0.931 lr:  0.00013527596\n",
      "Iter:  40 Loss:  1.5368099 Acc:  0.9312 lr:  0.00012851215\n",
      "Iter:  41 Loss:  1.5368518 Acc:  0.9305 lr:  0.00012208655\n",
      "Iter:  42 Loss:  1.5365657 Acc:  0.9312 lr:  0.00011598222\n",
      "Iter:  43 Loss:  1.5366328 Acc:  0.9308 lr:  0.00011018311\n",
      "Iter:  44 Loss:  1.5365205 Acc:  0.9314 lr:  0.000104673956\n",
      "Iter:  45 Loss:  1.536496 Acc:  0.9312 lr:  9.944026e-05\n",
      "Iter:  46 Loss:  1.5364634 Acc:  0.9316 lr:  9.446825e-05\n",
      "Iter:  47 Loss:  1.5365324 Acc:  0.9312 lr:  8.974483e-05\n",
      "Iter:  48 Loss:  1.5364275 Acc:  0.9312 lr:  8.525759e-05\n",
      "Iter:  49 Loss:  1.5363545 Acc:  0.9313 lr:  8.099471e-05\n",
      "Iter:  50 Loss:  1.5363219 Acc:  0.9313 lr:  7.6944976e-05\n",
      "Iter:  51 Loss:  1.5363373 Acc:  0.9311 lr:  7.3097726e-05\n",
      "Iter:  52 Loss:  1.536266 Acc:  0.9314 lr:  6.944284e-05\n",
      "Iter:  53 Loss:  1.5362973 Acc:  0.9312 lr:  6.59707e-05\n",
      "Iter:  54 Loss:  1.5363134 Acc:  0.9308 lr:  6.267217e-05\n",
      "Iter:  55 Loss:  1.5362216 Acc:  0.9313 lr:  5.9538554e-05\n",
      "Iter:  56 Loss:  1.536247 Acc:  0.9312 lr:  5.656163e-05\n",
      "Iter:  57 Loss:  1.5361917 Acc:  0.9313 lr:  5.3733547e-05\n",
      "Iter:  58 Loss:  1.5361801 Acc:  0.9313 lr:  5.1046867e-05\n",
      "Iter:  59 Loss:  1.5361375 Acc:  0.9313 lr:  4.8494527e-05\n",
      "Iter:  60 Loss:  1.5361271 Acc:  0.9317 lr:  4.60698e-05\n",
      "Iter:  61 Loss:  1.5360887 Acc:  0.9317 lr:  4.3766307e-05\n",
      "Iter:  62 Loss:  1.5361208 Acc:  0.9316 lr:  4.1577994e-05\n",
      "Iter:  63 Loss:  1.5361065 Acc:  0.9318 lr:  3.9499093e-05\n",
      "Iter:  64 Loss:  1.5360593 Acc:  0.9315 lr:  3.752414e-05\n",
      "Iter:  65 Loss:  1.5360615 Acc:  0.9315 lr:  3.5647932e-05\n",
      "Iter:  66 Loss:  1.536053 Acc:  0.9314 lr:  3.3865537e-05\n",
      "Iter:  67 Loss:  1.5360259 Acc:  0.9315 lr:  3.217226e-05\n",
      "Iter:  68 Loss:  1.5360402 Acc:  0.9316 lr:  3.0563646e-05\n",
      "Iter:  69 Loss:  1.5360098 Acc:  0.9315 lr:  2.9035464e-05\n",
      "Iter:  70 Loss:  1.5359907 Acc:  0.9315 lr:  2.758369e-05\n",
      "Iter:  71 Loss:  1.5359846 Acc:  0.9317 lr:  2.6204505e-05\n",
      "Iter:  72 Loss:  1.5359911 Acc:  0.9317 lr:  2.4894282e-05\n",
      "Iter:  73 Loss:  1.5359731 Acc:  0.9316 lr:  2.3649567e-05\n",
      "Iter:  74 Loss:  1.5359616 Acc:  0.9316 lr:  2.2467088e-05\n",
      "Iter:  75 Loss:  1.5359662 Acc:  0.9316 lr:  2.1343734e-05\n",
      "Iter:  76 Loss:  1.5359501 Acc:  0.9315 lr:  2.0276548e-05\n",
      "Iter:  77 Loss:  1.5359495 Acc:  0.9316 lr:  1.926272e-05\n",
      "Iter:  78 Loss:  1.5359379 Acc:  0.9317 lr:  1.8299585e-05\n",
      "Iter:  79 Loss:  1.53593 Acc:  0.9317 lr:  1.7384604e-05\n",
      "Iter:  80 Loss:  1.5359346 Acc:  0.9317 lr:  1.6515374e-05\n",
      "Iter:  81 Loss:  1.5359278 Acc:  0.9316 lr:  1.5689606e-05\n",
      "Iter:  82 Loss:  1.535919 Acc:  0.9319 lr:  1.4905126e-05\n",
      "Iter:  83 Loss:  1.5359155 Acc:  0.9318 lr:  1.4159869e-05\n",
      "Iter:  84 Loss:  1.5359063 Acc:  0.9316 lr:  1.3451876e-05\n",
      "Iter:  85 Loss:  1.5358994 Acc:  0.9318 lr:  1.2779282e-05\n",
      "Iter:  86 Loss:  1.535896 Acc:  0.9317 lr:  1.2140318e-05\n",
      "Iter:  87 Loss:  1.5358894 Acc:  0.9318 lr:  1.1533302e-05\n",
      "Iter:  88 Loss:  1.5358857 Acc:  0.9318 lr:  1.0956637e-05\n",
      "Iter:  89 Loss:  1.5358846 Acc:  0.9318 lr:  1.0408805e-05\n",
      "Iter:  90 Loss:  1.5358831 Acc:  0.9316 lr:  9.888365e-06\n",
      "Iter:  91 Loss:  1.535877 Acc:  0.9318 lr:  9.393946e-06\n",
      "Iter:  92 Loss:  1.535876 Acc:  0.9318 lr:  8.924249e-06\n",
      "Iter:  93 Loss:  1.5358676 Acc:  0.9318 lr:  8.478037e-06\n",
      "Iter:  94 Loss:  1.5358678 Acc:  0.9319 lr:  8.054135e-06\n",
      "Iter:  95 Loss:  1.5358624 Acc:  0.9318 lr:  7.651428e-06\n",
      "Iter:  96 Loss:  1.5358624 Acc:  0.9318 lr:  7.2688567e-06\n",
      "Iter:  97 Loss:  1.5358566 Acc:  0.9318 lr:  6.905414e-06\n",
      "Iter:  98 Loss:  1.5358593 Acc:  0.9318 lr:  6.560143e-06\n",
      "Iter:  99 Loss:  1.5358545 Acc:  0.9318 lr:  6.232136e-06\n",
      "Iter:  100 Loss:  1.535853 Acc:  0.9317 lr:  5.920529e-06\n",
      "Iter:  101 Loss:  1.5358522 Acc:  0.9318 lr:  5.6245026e-06\n",
      "Iter:  102 Loss:  1.53585 Acc:  0.9318 lr:  5.3432777e-06\n",
      "Iter:  103 Loss:  1.5358486 Acc:  0.9318 lr:  5.0761137e-06\n",
      "Iter:  104 Loss:  1.5358459 Acc:  0.9318 lr:  4.8223083e-06\n",
      "Iter:  105 Loss:  1.5358455 Acc:  0.9318 lr:  4.5811926e-06\n",
      "Iter:  106 Loss:  1.5358436 Acc:  0.9318 lr:  4.352133e-06\n",
      "Iter:  107 Loss:  1.5358409 Acc:  0.9318 lr:  4.1345265e-06\n",
      "Iter:  108 Loss:  1.5358409 Acc:  0.9318 lr:  3.9278e-06\n",
      "Iter:  109 Loss:  1.5358379 Acc:  0.9317 lr:  3.73141e-06\n",
      "Iter:  110 Loss:  1.5358375 Acc:  0.9317 lr:  3.5448395e-06\n",
      "Iter:  111 Loss:  1.5358362 Acc:  0.9317 lr:  3.3675976e-06\n",
      "Iter:  112 Loss:  1.5358349 Acc:  0.9317 lr:  3.1992176e-06\n",
      "Iter:  113 Loss:  1.5358349 Acc:  0.9317 lr:  3.0392569e-06\n",
      "Iter:  114 Loss:  1.5358329 Acc:  0.9317 lr:  2.887294e-06\n",
      "Iter:  115 Loss:  1.5358323 Acc:  0.9317 lr:  2.7429292e-06\n",
      "Iter:  116 Loss:  1.5358318 Acc:  0.9317 lr:  2.6057828e-06\n",
      "Iter:  117 Loss:  1.5358301 Acc:  0.9317 lr:  2.4754936e-06\n",
      "Iter:  118 Loss:  1.5358303 Acc:  0.9317 lr:  2.3517189e-06\n",
      "Iter:  119 Loss:  1.5358291 Acc:  0.9317 lr:  2.234133e-06\n",
      "Iter:  120 Loss:  1.5358282 Acc:  0.9317 lr:  2.1224264e-06\n",
      "Iter:  121 Loss:  1.5358278 Acc:  0.9317 lr:  2.016305e-06\n",
      "Iter:  122 Loss:  1.5358274 Acc:  0.9317 lr:  1.9154897e-06\n",
      "Iter:  123 Loss:  1.5358267 Acc:  0.9317 lr:  1.8197153e-06\n",
      "Iter:  124 Loss:  1.535826 Acc:  0.9317 lr:  1.7287296e-06\n",
      "Iter:  125 Loss:  1.5358257 Acc:  0.9317 lr:  1.6422931e-06\n",
      "Iter:  126 Loss:  1.5358253 Acc:  0.9317 lr:  1.5601785e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  127 Loss:  1.5358247 Acc:  0.9317 lr:  1.4821695e-06\n",
      "Iter:  128 Loss:  1.5358242 Acc:  0.9317 lr:  1.408061e-06\n",
      "Iter:  129 Loss:  1.5358238 Acc:  0.9317 lr:  1.337658e-06\n",
      "Iter:  130 Loss:  1.5358232 Acc:  0.9317 lr:  1.2707751e-06\n",
      "Iter:  131 Loss:  1.5358225 Acc:  0.9317 lr:  1.2072363e-06\n",
      "Iter:  132 Loss:  1.5358223 Acc:  0.9317 lr:  1.1468745e-06\n",
      "Iter:  133 Loss:  1.5358219 Acc:  0.9317 lr:  1.0895308e-06\n",
      "Iter:  134 Loss:  1.5358214 Acc:  0.9317 lr:  1.0350542e-06\n",
      "Iter:  135 Loss:  1.5358211 Acc:  0.9317 lr:  9.833016e-07\n",
      "Iter:  136 Loss:  1.5358208 Acc:  0.9317 lr:  9.3413644e-07\n",
      "Iter:  137 Loss:  1.5358205 Acc:  0.9317 lr:  8.874296e-07\n",
      "Iter:  138 Loss:  1.5358202 Acc:  0.9317 lr:  8.4305816e-07\n",
      "Iter:  139 Loss:  1.5358201 Acc:  0.9317 lr:  8.0090524e-07\n",
      "Iter:  140 Loss:  1.5358199 Acc:  0.9317 lr:  7.6085996e-07\n",
      "Iter:  141 Loss:  1.5358195 Acc:  0.9317 lr:  7.22817e-07\n",
      "Iter:  142 Loss:  1.5358194 Acc:  0.9317 lr:  6.866761e-07\n",
      "Iter:  143 Loss:  1.5358193 Acc:  0.9317 lr:  6.5234235e-07\n",
      "Iter:  144 Loss:  1.535819 Acc:  0.9317 lr:  6.197252e-07\n",
      "Iter:  145 Loss:  1.5358187 Acc:  0.9317 lr:  5.8873894e-07\n",
      "Iter:  146 Loss:  1.5358185 Acc:  0.9317 lr:  5.59302e-07\n",
      "Iter:  147 Loss:  1.5358183 Acc:  0.9317 lr:  5.313369e-07\n",
      "Iter:  148 Loss:  1.5358182 Acc:  0.9317 lr:  5.0477007e-07\n",
      "Iter:  149 Loss:  1.5358182 Acc:  0.9317 lr:  4.7953154e-07\n",
      "Iter:  150 Loss:  1.5358177 Acc:  0.9317 lr:  4.5555498e-07\n",
      "Iter:  151 Loss:  1.5358177 Acc:  0.9317 lr:  4.3277723e-07\n",
      "Iter:  152 Loss:  1.5358176 Acc:  0.9317 lr:  4.1113836e-07\n",
      "Iter:  153 Loss:  1.5358176 Acc:  0.9317 lr:  3.9058145e-07\n",
      "Iter:  154 Loss:  1.5358175 Acc:  0.9317 lr:  3.7105238e-07\n",
      "Iter:  155 Loss:  1.5358173 Acc:  0.9317 lr:  3.5249977e-07\n",
      "Iter:  156 Loss:  1.5358171 Acc:  0.9317 lr:  3.3487476e-07\n",
      "Iter:  157 Loss:  1.535817 Acc:  0.9317 lr:  3.1813104e-07\n",
      "Iter:  158 Loss:  1.5358171 Acc:  0.9317 lr:  3.0222446e-07\n",
      "Iter:  159 Loss:  1.5358169 Acc:  0.9317 lr:  2.8711327e-07\n",
      "Iter:  160 Loss:  1.5358168 Acc:  0.9317 lr:  2.727576e-07\n",
      "Iter:  161 Loss:  1.5358168 Acc:  0.9317 lr:  2.591197e-07\n",
      "Iter:  162 Loss:  1.5358168 Acc:  0.9317 lr:  2.4616372e-07\n",
      "Iter:  163 Loss:  1.5358166 Acc:  0.9317 lr:  2.3385554e-07\n",
      "Iter:  164 Loss:  1.5358166 Acc:  0.9317 lr:  2.2216277e-07\n",
      "Iter:  165 Loss:  1.5358166 Acc:  0.9317 lr:  2.1105463e-07\n",
      "Iter:  166 Loss:  1.5358166 Acc:  0.9317 lr:  2.0050189e-07\n",
      "Iter:  167 Loss:  1.5358166 Acc:  0.9317 lr:  1.904768e-07\n",
      "Iter:  168 Loss:  1.5358164 Acc:  0.9317 lr:  1.8095295e-07\n",
      "Iter:  169 Loss:  1.5358162 Acc:  0.9317 lr:  1.7190531e-07\n",
      "Iter:  170 Loss:  1.5358164 Acc:  0.9317 lr:  1.6331005e-07\n",
      "Iter:  171 Loss:  1.5358164 Acc:  0.9317 lr:  1.5514455e-07\n",
      "Iter:  172 Loss:  1.5358161 Acc:  0.9317 lr:  1.4738731e-07\n",
      "Iter:  173 Loss:  1.5358161 Acc:  0.9317 lr:  1.4001795e-07\n",
      "Iter:  174 Loss:  1.5358162 Acc:  0.9317 lr:  1.3301705e-07\n",
      "Iter:  175 Loss:  1.5358162 Acc:  0.9317 lr:  1.263662e-07\n",
      "Iter:  176 Loss:  1.5358161 Acc:  0.9317 lr:  1.2004789e-07\n",
      "Iter:  177 Loss:  1.5358161 Acc:  0.9317 lr:  1.140455e-07\n",
      "Iter:  178 Loss:  1.5358161 Acc:  0.9317 lr:  1.0834322e-07\n",
      "Iter:  179 Loss:  1.5358161 Acc:  0.9317 lr:  1.0292606e-07\n",
      "Iter:  180 Loss:  1.5358161 Acc:  0.9317 lr:  9.7779754e-08\n",
      "Iter:  181 Loss:  1.5358161 Acc:  0.9317 lr:  9.2890765e-08\n",
      "Iter:  182 Loss:  1.5358161 Acc:  0.9317 lr:  8.824623e-08\n",
      "Iter:  183 Loss:  1.5358161 Acc:  0.9317 lr:  8.383392e-08\n",
      "Iter:  184 Loss:  1.5358161 Acc:  0.9317 lr:  7.964222e-08\n",
      "Iter:  185 Loss:  1.5358161 Acc:  0.9317 lr:  7.566011e-08\n",
      "Iter:  186 Loss:  1.5358161 Acc:  0.9317 lr:  7.18771e-08\n",
      "Iter:  187 Loss:  1.5358161 Acc:  0.9317 lr:  6.828325e-08\n",
      "Iter:  188 Loss:  1.5358162 Acc:  0.9317 lr:  6.486909e-08\n",
      "Iter:  189 Loss:  1.5358161 Acc:  0.9317 lr:  6.1625634e-08\n",
      "Iter:  190 Loss:  1.5358161 Acc:  0.9317 lr:  5.854435e-08\n",
      "Iter:  191 Loss:  1.5358161 Acc:  0.9317 lr:  5.5617136e-08\n",
      "Iter:  192 Loss:  1.5358162 Acc:  0.9317 lr:  5.2836278e-08\n",
      "Iter:  193 Loss:  1.5358161 Acc:  0.9317 lr:  5.0194465e-08\n",
      "Iter:  194 Loss:  1.5358161 Acc:  0.9317 lr:  4.768474e-08\n",
      "Iter:  195 Loss:  1.5358162 Acc:  0.9317 lr:  4.5300503e-08\n",
      "Iter:  196 Loss:  1.5358161 Acc:  0.9317 lr:  4.3035477e-08\n",
      "Iter:  197 Loss:  1.5358162 Acc:  0.9317 lr:  4.0883705e-08\n",
      "Iter:  198 Loss:  1.5358161 Acc:  0.9317 lr:  3.883952e-08\n",
      "Iter:  199 Loss:  1.5358161 Acc:  0.9317 lr:  3.6897543e-08\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    for epoch in range(200):\n",
    "        sess.run(tf.assign(lr, 0.001 * (0.95 ** epoch)))\n",
    "        for batch in range(n_batchs):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict = {x:batch_x, y:batch_y, keep_prob:0.5})\n",
    "            writer.add_summary(summary, epoch * n_batchs + batch)\n",
    "        loss_value, acc, lr_value = sess.run([loss, accuracy, lr], feed_dict = {x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "        print(\"Iter: \", epoch, \"Loss: \", loss_value, \"Acc: \", acc, \"lr: \", lr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
