{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的保存与恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7ad1921416f6>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置参数batch_size的大小，计算迭代的总批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.truncated_normal([784,10], stddev=0.1))\n",
    "b = tf.Variable(tf.zeros([10]) + 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(tf.matmul(x, w) + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义初始化的init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义保存的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 Loss: 1.9611119, Testing Acc: 0.6927\n",
      "Iter: 1 Loss: 1.7913371, Testing Acc: 0.8105\n",
      "Iter: 2 Loss: 1.7237637, Testing Acc: 0.842\n",
      "Iter: 3 Loss: 1.6858625, Testing Acc: 0.8586\n",
      "Iter: 4 Loss: 1.6611539, Testing Acc: 0.8721\n",
      "Iter: 5 Loss: 1.6434838, Testing Acc: 0.8812\n",
      "Iter: 6 Loss: 1.6301237, Testing Acc: 0.8875\n",
      "Iter: 7 Loss: 1.6198373, Testing Acc: 0.8925\n",
      "Iter: 8 Loss: 1.6114361, Testing Acc: 0.8961\n",
      "Iter: 9 Loss: 1.6045126, Testing Acc: 0.8993\n",
      "Iter: 10 Loss: 1.598698, Testing Acc: 0.9018\n",
      "Iter: 11 Loss: 1.5938588, Testing Acc: 0.9037\n",
      "Iter: 12 Loss: 1.5896755, Testing Acc: 0.9055\n",
      "Iter: 13 Loss: 1.5861481, Testing Acc: 0.9066\n",
      "Iter: 14 Loss: 1.583019, Testing Acc: 0.9078\n",
      "Iter: 15 Loss: 1.5802971, Testing Acc: 0.9092\n",
      "Iter: 16 Loss: 1.5779793, Testing Acc: 0.9112\n",
      "Iter: 17 Loss: 1.5756525, Testing Acc: 0.9119\n",
      "Iter: 18 Loss: 1.5738477, Testing Acc: 0.9121\n",
      "Iter: 19 Loss: 1.5720111, Testing Acc: 0.9138\n",
      "Iter: 20 Loss: 1.5704764, Testing Acc: 0.9147\n",
      "Iter: 21 Loss: 1.5688945, Testing Acc: 0.9147\n",
      "Iter: 22 Loss: 1.5676639, Testing Acc: 0.9158\n",
      "Iter: 23 Loss: 1.5663022, Testing Acc: 0.9161\n",
      "Iter: 24 Loss: 1.5651513, Testing Acc: 0.9166\n",
      "Iter: 25 Loss: 1.5641531, Testing Acc: 0.9168\n",
      "Iter: 26 Loss: 1.5631107, Testing Acc: 0.9172\n",
      "Iter: 27 Loss: 1.5620006, Testing Acc: 0.9184\n",
      "Iter: 28 Loss: 1.5612909, Testing Acc: 0.9187\n",
      "Iter: 29 Loss: 1.5603019, Testing Acc: 0.9191\n",
      "Iter: 30 Loss: 1.5596213, Testing Acc: 0.9196\n",
      "Iter: 31 Loss: 1.5589631, Testing Acc: 0.9198\n",
      "Iter: 32 Loss: 1.558082, Testing Acc: 0.9207\n",
      "Iter: 33 Loss: 1.5576842, Testing Acc: 0.9199\n",
      "Iter: 34 Loss: 1.5570347, Testing Acc: 0.9206\n",
      "Iter: 35 Loss: 1.5564219, Testing Acc: 0.9213\n",
      "Iter: 36 Loss: 1.5559012, Testing Acc: 0.921\n",
      "Iter: 37 Loss: 1.5552123, Testing Acc: 0.9218\n",
      "Iter: 38 Loss: 1.5547487, Testing Acc: 0.9218\n",
      "Iter: 39 Loss: 1.5542457, Testing Acc: 0.9223\n",
      "Iter: 40 Loss: 1.5537552, Testing Acc: 0.9224\n",
      "Iter: 41 Loss: 1.5532919, Testing Acc: 0.9231\n",
      "Iter: 42 Loss: 1.5528114, Testing Acc: 0.9234\n",
      "Iter: 43 Loss: 1.5525187, Testing Acc: 0.9236\n",
      "Iter: 44 Loss: 1.5521034, Testing Acc: 0.9235\n",
      "Iter: 45 Loss: 1.5517327, Testing Acc: 0.9242\n",
      "Iter: 46 Loss: 1.5514243, Testing Acc: 0.924\n",
      "Iter: 47 Loss: 1.5509135, Testing Acc: 0.9242\n",
      "Iter: 48 Loss: 1.5507, Testing Acc: 0.9244\n",
      "Iter: 49 Loss: 1.5502166, Testing Acc: 0.9251\n",
      "Iter: 50 Loss: 1.5498794, Testing Acc: 0.9257\n",
      "Iter: 51 Loss: 1.5495678, Testing Acc: 0.9255\n",
      "Iter: 52 Loss: 1.549402, Testing Acc: 0.9255\n",
      "Iter: 53 Loss: 1.5490623, Testing Acc: 0.926\n",
      "Iter: 54 Loss: 1.548652, Testing Acc: 0.9263\n",
      "Iter: 55 Loss: 1.5485433, Testing Acc: 0.9261\n",
      "Iter: 56 Loss: 1.5482138, Testing Acc: 0.9267\n",
      "Iter: 57 Loss: 1.547948, Testing Acc: 0.9263\n",
      "Iter: 58 Loss: 1.5476035, Testing Acc: 0.927\n",
      "Iter: 59 Loss: 1.5474508, Testing Acc: 0.9267\n",
      "Iter: 60 Loss: 1.5472238, Testing Acc: 0.9269\n",
      "Iter: 61 Loss: 1.5468897, Testing Acc: 0.927\n",
      "Iter: 62 Loss: 1.5466827, Testing Acc: 0.9272\n",
      "Iter: 63 Loss: 1.5464674, Testing Acc: 0.9276\n",
      "Iter: 64 Loss: 1.5462357, Testing Acc: 0.9275\n",
      "Iter: 65 Loss: 1.5460459, Testing Acc: 0.9274\n",
      "Iter: 66 Loss: 1.5458452, Testing Acc: 0.9276\n",
      "Iter: 67 Loss: 1.5455347, Testing Acc: 0.928\n",
      "Iter: 68 Loss: 1.5454332, Testing Acc: 0.9276\n",
      "Iter: 69 Loss: 1.5452516, Testing Acc: 0.9277\n",
      "Iter: 70 Loss: 1.5450586, Testing Acc: 0.9282\n",
      "Iter: 71 Loss: 1.5448893, Testing Acc: 0.9279\n",
      "Iter: 72 Loss: 1.5446728, Testing Acc: 0.9281\n",
      "Iter: 73 Loss: 1.5444536, Testing Acc: 0.9283\n",
      "Iter: 74 Loss: 1.544341, Testing Acc: 0.928\n",
      "Iter: 75 Loss: 1.544166, Testing Acc: 0.9284\n",
      "Iter: 76 Loss: 1.5439602, Testing Acc: 0.9287\n",
      "Iter: 77 Loss: 1.543906, Testing Acc: 0.9288\n",
      "Iter: 78 Loss: 1.543584, Testing Acc: 0.929\n",
      "Iter: 79 Loss: 1.5434943, Testing Acc: 0.9292\n",
      "Iter: 80 Loss: 1.5433578, Testing Acc: 0.9287\n",
      "Iter: 81 Loss: 1.5432125, Testing Acc: 0.9288\n",
      "Iter: 82 Loss: 1.54311, Testing Acc: 0.9289\n",
      "Iter: 83 Loss: 1.5429647, Testing Acc: 0.9291\n",
      "Iter: 84 Loss: 1.5427074, Testing Acc: 0.9291\n",
      "Iter: 85 Loss: 1.5427395, Testing Acc: 0.929\n",
      "Iter: 86 Loss: 1.5424964, Testing Acc: 0.9294\n",
      "Iter: 87 Loss: 1.5424142, Testing Acc: 0.929\n",
      "Iter: 88 Loss: 1.5422841, Testing Acc: 0.9291\n",
      "Iter: 89 Loss: 1.5422442, Testing Acc: 0.9295\n",
      "Iter: 90 Loss: 1.5420259, Testing Acc: 0.929\n",
      "Iter: 91 Loss: 1.541924, Testing Acc: 0.9293\n",
      "Iter: 92 Loss: 1.5417726, Testing Acc: 0.9297\n",
      "Iter: 93 Loss: 1.5416414, Testing Acc: 0.9294\n",
      "Iter: 94 Loss: 1.5415725, Testing Acc: 0.9299\n",
      "Iter: 95 Loss: 1.5414269, Testing Acc: 0.9298\n",
      "Iter: 96 Loss: 1.5413296, Testing Acc: 0.9295\n",
      "Iter: 97 Loss: 1.541231, Testing Acc: 0.9298\n",
      "Iter: 98 Loss: 1.5411233, Testing Acc: 0.9303\n",
      "Iter: 99 Loss: 1.5409867, Testing Acc: 0.9301\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(100):\n",
    "        for batch in range(n_batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run([train_step], {x:batch_xs, y:batch_ys})\n",
    "        saver.save(sess, save_path='saved_model/mymodel')\n",
    "        acc, loss = sess.run([accuracy, cross_entropy], {x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"Iter: \" + str(epoch) + \" Loss: \" + str(loss) + \", Testing Acc: \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恢复模型进行对比\n",
    "1. 未恢复参数的模型效果\n",
    "2. 完全恢复模型参数的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.3044705, Testing Acc: 0.0996\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    acc, loss = sess.run([accuracy, cross_entropy], {x:mnist.test.images, y:mnist.test.labels})\n",
    "    print(\" Loss: \" + str(loss) + \", Testing Acc: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/mymodel\n",
      " Loss: 1.5409867, Testing Acc: 0.9301\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, 'saved_model/mymodel')\n",
    "    acc, loss = sess.run([accuracy, cross_entropy], {x:mnist.test.images, y:mnist.test.labels})\n",
    "    print(\" Loss: \" + str(loss) + \", Testing Acc: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
